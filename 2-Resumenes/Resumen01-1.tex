\documentclass[aspectratio=169]{beamer}
% -- Formato
\input{formatoBeamer}

% -- Paquetes adicionales
\usepackage{aleph-comandos}
\usepackage{enumitem}
\usepackage{multicol}
\usepackage{tikz}

% -- Comandos extra


% -- Datos
\title{Introducción al Aprendizaje Automático}
\author{Andrés Merino T.}
% \institute{Fundamentos de Machine Learning}
\date{Febrero 2026}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% -- Página de título
\fondo{inicio}
\begin{frame}[plain]
\addtocounter{framenumber}{-1}
    \titlepage
\end{frame}

\fondo{blanco}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\fondo{celeste}
\section{Hitos de la Inteligencia Artificial}
\fondo{blanco}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[t]{Hitos de la Inteligencia Artificial}
\begin{columns}
\column{.45\textwidth}    
    \begin{itemize}[leftmargin=*]
        \item \textbf{1943:} Primer modelo de neurona artificial (McCulloch y Pitts).
        \item \textbf{1950:} Turing propone el «{Test de Turing}».
        \item \textbf{1956:} Conferencia de Dartmouth, se acuña el término «{Inteligencia Artificial}» (McCarthy).
    \end{itemize}
\column{.53\textwidth}
    \postitimg[0.95\linewidth]{2-Resumenes/img/Dartmouth.jpg}
\end{columns}
\end{frame}
\begin{frame}[t]{Hitos de la Inteligencia Artificial}
    \begin{itemize}[leftmargin=*]
        \item \textbf{1966:} {ELIZA}, el primer chatbot (lenguaje natural básico).
        \item \textbf{1974-1980:} Primer «{Invierno de la IA}», cortes de financiación.
        \item \textbf{1997:} Deep Blue (IBM) derrota a Garry Kasparov (ajedrez).
        \item \textbf{2016:} AlphaGo (Google) derrota a Lee Sedol (Go).
        \item \textbf{2022:} Lanzamiento público de ChatGPT.
        \item \textbf{2023-Presente:} Era de la IA Generativa.
    \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\fondo{celeste}
\section{Definición de IA}
\fondo{blanco}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Principales Definiciones de IA}
\begin{columns}
\column{.65\textwidth}
    \begin{block}{Alan Turing (1950)}
        La inteligencia se define por si puede \textbf{actuar de manera indistinguible} de un humano (Test de Turing).
    \end{block}
\column{.3\textwidth}
    \postitimg[0.95\linewidth]{2-Resumenes/img/Turing.jpg}

\end{columns}
\end{frame}
\begin{frame}[t]{Principales Definiciones de IA}
\begin{columns}
\column{.65\textwidth}
    \begin{block}{Claude Shannon et al. (1955 - Dartmouth)}
        Cada aspecto del aprendizaje o cualquier otra característica de la inteligencia puede describirse con tanta precisión que se pueda construir una máquina que lo simule.
    \end{block}
\column{.3\textwidth}
    \postitimg[0.95\linewidth]{2-Resumenes/img/Claude.jpg}
\end{columns}
\end{frame}

\begin{frame}[t]{Principales Definiciones de IA}
    \begin{block}{Marvin Minsky (1967)}
        La inteligencia artificial es la ciencia de hacer que las máquinas hagan cosas que requerirían inteligencia si las hiciera un humano.
    \end{block}
    
    \begin{block}{Stuart Russell (1995)}
        La IA es el estudio de agentes que reciben percepciones del entorno y realizan acciones.
    \end{block}
\end{frame}

\begin{frame}[t]{Principales Definiciones de IA}
    \begin{block}{Nils J. Nilsson (2005)}
        El estudio del comportamiento inteligente en las máquinas – es decir, diseñar sistemas que perciban, razonen, aprendan, se comuniquen y actúen en entornos complejos
    \end{block}

    \begin{block}{Comisión Europea (Ley de IA - 2024)}
        Sistemas basados en máquinas que {infieren} a partir de la entrada cómo generar salidas (predicciones, contenido) que {influyen} en entornos físicos o virtuales.
    \end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\fondo{celeste}
\section{Definición de Aprendizaje Automático}
\fondo{blanco}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Definiciones de Aprendizaje Automático (Machine Learning)}

    \begin{block}{Arthur Samuel (1959)}
        El campo de estudio que da a las computadoras la capacidad de aprender sin ser explícitamente programadas.
    \end{block}

    \begin{block}{Tom Mitchell (1997) - Definición Formal}
        Se dice que un programa de computadora aprende de la {experiencia $E$} con respecto a alguna clase de {tareas $T$} y medida de {desempeño $P$}, si su desempeño en $T$, medido por $P$, {mejora con la experiencia $E$}.
    \end{block}
\end{frame}

% --- Diapositiva 4: Hitos del Aprendizaje Automático ---
\begin{frame}[t]{Hitos del Aprendizaje Automático}
    \begin{itemize}
        \item \textbf{1958:} Frank Rosenblatt crea el «{Perceptrón}», la primera red neuronal capaz de aprender patrones simples.
        \item \textbf{1969:} Minsky y Papert publican «{Perceptrons}». Demuestran que las redes de una capa no podían resolver problemas {no lineales} (como XOR). Congeló la investigación.
        \item \textbf{1986:} Rumelhart, Hinton y Williams popularizan el algoritmo de «{Backpropagation}» (retropropagación), permitiendo entrenar {redes neuronales profundas} (multicapa).
    \end{itemize}
\end{frame}
\begin{frame}[t]{Hitos del Aprendizaje Automático}
    \begin{itemize}
        \item \textbf{1990s:} Cambio al enfoque {estadístico} (Statistical Shift). Dominio de algoritmos como {Support Vector Machines} (SVM) y {Random Forests}.
        \item \textbf{2012:} {AlexNet}, una red neuronal convolucional profunda gana la competición ImageNet, detonando la revolución del {Deep Learning}.
        \item \textbf{2017:} Publicación de «{Attention Is All You Need}». Introducción de la arquitectura «{Transformer}», base de todos los Modelos de Lenguaje Grande (LLM) actuales.
    \end{itemize}
\end{frame}

\end{document}